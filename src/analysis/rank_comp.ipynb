{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76cb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata, spearmanr\n",
    "from scipy.stats import wilcoxon\n",
    "import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7802bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df = pd.read_csv('/mnt/c/Users/donna/Downloads/Thesis/rankjes/paper_ranks/03x_matched_reference_ranks.csv', usecols=['tissue', 'rank', \"cell_type\", \"GC_code\"])\n",
    "paper_df['tissue'] = paper_df['tissue'].str.lower()\n",
    "paper_df['cell_type'] = paper_df['cell_type'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c316f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_dir = '/mnt/c/Users/donna/Downloads/Thesis/correlation_results/scrna/cov_spread_brca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d11bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare result storage\n",
    "results = []\n",
    "ranks_dir = \"/mnt/c/Users/donna/Downloads/Thesis/rankjes\"\n",
    "os.makedirs(ranks_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a74452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_medians = (\n",
    "    paper_df.groupby(\"tissue\")[\"rank\"]\n",
    "    .median()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e233c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_word_tissues = {\n",
    "    'small_intestine',\n",
    "    'large_intestine',\n",
    "    'salivary_gland',\n",
    "    'bone_marrow',\n",
    "    'lymph_node'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd9715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Niet lopen over fragment features\n",
    "# Load all correlation matrices\n",
    "correlation_matrices = {}\n",
    "for file in os.listdir(corr_matrix_dir):\n",
    "    if file.endswith('.csv'):\n",
    "        tissue_name = os.path.splitext(file)[0].lower()\n",
    "        matrix = pd.read_csv(os.path.join(corr_matrix_dir, file), index_col=0)\n",
    "        correlation_matrices[tissue_name] = matrix\n",
    "\n",
    "# Rank all cell types across tissues within each sample\n",
    "sample_wise_corrs = {}\n",
    "for tissue_name, matrix in correlation_matrices.items():\n",
    "    for sample_name in matrix.index:  # sample = row\n",
    "        for cell_type in matrix.columns:  # cell type = column\n",
    "            value = matrix.loc[sample_name, cell_type]\n",
    "            if not np.isnan(value):\n",
    "                sample_wise_corrs.setdefault(sample_name, []).append(\n",
    "                    (cell_type, tissue_name, value)  # keep tissue separate\n",
    "                )\n",
    "\n",
    "# Compute and collect rank data\n",
    "rank_data = []\n",
    "for sample_name, items in sample_wise_corrs.items():\n",
    "    cell_types, tissues, values = zip(*items)  # unpack all three fields\n",
    "    values = np.array(values)\n",
    "    ranks = rankdata(values, method='ordinal')\n",
    "    ranks = len(ranks) + 1 - ranks  # flip: highest correlation = rank 1\n",
    "\n",
    "    for cell_type, tissue, rank in zip(cell_types, tissues, ranks):\n",
    "        rank_data.append({\n",
    "            'sample': sample_name,\n",
    "            'cell_type': f\"{cell_type}_{tissue}\",\n",
    "            'tissue': tissue,\n",
    "            'rank': rank,\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "df_ranks = pd.DataFrame(rank_data)\n",
    "output_path = \"/mnt/c/Users/donna/Downloads/Thesis/rankjes/brca_cov_spread_ranks.csv\"\n",
    "df_ranks.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d12428",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/mnt/c/Users/donna/Downloads/Thesis/correlation_results/scrna/control/abs_cors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c7405bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loopen over fragment features\n",
    "results = []\n",
    "\n",
    "for feature in os.listdir(base_dir):\n",
    "    feature_path = os.path.join(base_dir, feature)\n",
    "    if not os.path.isdir(feature_path):\n",
    "        continue\n",
    "\n",
    "    # Load all correlation matrices for this feature\n",
    "    correlation_matrices = {}\n",
    "    for file in os.listdir(feature_path):\n",
    "        if file.endswith('.csv'):\n",
    "            tissue_name = os.path.splitext(file)[0].lower()\n",
    "            matrix = pd.read_csv(os.path.join(feature_path, file), index_col=0)\n",
    "            correlation_matrices[tissue_name] = matrix\n",
    "\n",
    "    # Rank all cell types across tissues within each sample\n",
    "    sample_wise_corrs = {}\n",
    "    for tissue_name, matrix in correlation_matrices.items():\n",
    "        for sample_name in matrix.columns:\n",
    "            for cell_type in matrix.index:\n",
    "                value = matrix.loc[cell_type, sample_name]\n",
    "                if not np.isnan(value):\n",
    "                    sample_wise_corrs.setdefault(sample_name, []).append(\n",
    "                        (f'{cell_type}_{tissue_name}', value)\n",
    "                    )\n",
    "\n",
    "    #### Hier gebleven\n",
    "    rank_data = []\n",
    "    for sample_name, items in sample_wise_corrs.items():\n",
    "        # Every sample contains all cell types with corresponding correlation values\n",
    "        cell_types, values = zip(*items)\n",
    "        values = np.array(values)\n",
    "\n",
    "        # Calculates ranks per sample\n",
    "        ranks = rankdata(values, method='ordinal')\n",
    "        ranks = len(ranks) + 1 - ranks  # flip: highest correlation = rank 1\n",
    "\n",
    "        for cell_type, rank in zip(cell_types, ranks):\n",
    "            # Split the cell_type by underscores\n",
    "            parts = cell_type.split('_')\n",
    "\n",
    "            last_two = '_'.join(parts[-2:])\n",
    "            last_one = parts[-1]\n",
    "\n",
    "            if last_two in two_word_tissues:\n",
    "                tissue = last_two\n",
    "                original_cell_type = '_'.join(parts[:-2])\n",
    "\n",
    "\n",
    "            else:\n",
    "                tissue = last_one\n",
    "                original_cell_type = '_'.join(parts[:-1])\n",
    "\n",
    "        \n",
    "\n",
    "            rank_data.append({\n",
    "                'cell_type': f\"{original_cell_type}_{tissue}\",\n",
    "                'rank': rank,\n",
    "                'sample': sample_name,\n",
    "                'tissue': tissue,\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_ranks = pd.DataFrame(rank_data)\n",
    "\n",
    "    # Save DataFrame to CSV \n",
    "    output_path = os.path.join(\"/mnt/c/Users/donna/Downloads/Thesis/rankjes/abscor_ranks_per_feature\", f\"{feature}_rank_results.csv\")\n",
    "    df_ranks.to_csv(output_path, index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf272ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/mnt/c/Users/donna/Downloads/Thesis/rankjes/abscor_ranks_per_feature'\n",
    "paper_path = '/mnt/c/Users/donna/Downloads/Thesis/rankjes/paper_ranks'\n",
    "\n",
    "#Extract coverage depths\n",
    "paper_depth_files = [f for f in os.listdir(paper_path) if f.endswith('.csv')]\n",
    "paper_depths = [f.split('_')[0] for f in paper_depth_files] \n",
    "paper_df['tissue'] = paper_df['tissue'].str.lower()\n",
    "paper_df['cell_type'] = paper_df['cell_type'].str.lower()\n",
    "\n",
    "summary_results = []\n",
    "\n",
    "# Loop over your fragment feature CSVs\n",
    "for my_file in os.listdir(my_path):\n",
    "    if not my_file.endswith('.csv'):\n",
    "        continue\n",
    "    feature = my_file.split('_results')[0]\n",
    "    my_df = pd.read_csv(os.path.join(my_path, my_file))\n",
    "\n",
    "    #Calculate median rank per cell_type for current feature\n",
    "    my_median = my_df.groupby('cell_type')['rank'].median().reset_index().rename(columns={'rank': 'median_rank_my'})\n",
    "\n",
    "    feature_result = {'feature': feature}\n",
    "    #Loop over the diff coverage depths\n",
    "    for paper_file, depth in zip(paper_depth_files, paper_depths):\n",
    "        paper_df = pd.read_csv(os.path.join(paper_path, paper_file))\n",
    "        paper_df['tissue'] = paper_df['tissue'].str.lower()\n",
    "        paper_df['cell_type'] = paper_df['cell_type'].apply(lambda x: '_'.join(x.rsplit('_', 1)[:-1] + [x.rsplit('_', 1)[-1].lower()]) if '_' in x else x.lower())\n",
    "\n",
    "\n",
    "        #Calculate median rank per cell_type for current cov depth\n",
    "        paper_median = paper_df.groupby('cell_type')['rank'].median().reset_index().rename(columns={'rank': f'median_rank_{depth}'})\n",
    "\n",
    "\n",
    "        #Merge on cell_type\n",
    "        merged_df = pd.merge(my_median, paper_median, on='cell_type')\n",
    "\n",
    "        my_ranks = merged_df['median_rank_my']\n",
    "        paper_ranks = merged_df[f'median_rank_{depth}']\n",
    "\n",
    "        #Calc corr and p-value\n",
    "        spearman_corr, spearman_p = spearmanr(my_ranks, paper_ranks)\n",
    "\n",
    "        # Store corr per coverage depth\n",
    "        feature_result[f'corr_{depth}'] = spearman_corr\n",
    "        feature_result[f'pval_{depth}'] = spearman_p\n",
    "      \n",
    "\n",
    "    summary_results.append(feature_result)\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "summary_df.to_csv('/mnt/c/Users/donna/Downloads/Thesis/rankjes/spearmann_rank_corr.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a10415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paired Rank Sum Test\n",
    "from scipy.stats import wilcoxon\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "my_path = '/mnt/c/Users/donna/Downloads/Thesis/rankjes/abscor_ranks_per_feature'\n",
    "paper_path = '/mnt/c/Users/donna/Downloads/Thesis/rankjes/paper_ranks'\n",
    "\n",
    "# Extract coverage depths\n",
    "paper_depth_files = [f for f in os.listdir(paper_path) if f.endswith('.csv')]\n",
    "paper_depths = [f.split('_')[0] for f in paper_depth_files] \n",
    "\n",
    "\n",
    "summary_results = []\n",
    "\n",
    "# Loop over your fragment feature CSVs\n",
    "for my_file in os.listdir(my_path):\n",
    "    if not my_file.endswith('.csv'):\n",
    "        continue\n",
    "    feature = my_file.split('_results')[0]\n",
    "    my_df = pd.read_csv(os.path.join(my_path, my_file))\n",
    "\n",
    "    # Calculate median rank per cell_type for current feature\n",
    "    my_median = my_df.groupby('cell_type')['rank'].median().reset_index().rename(columns={'rank': 'median_rank_my'})\n",
    "\n",
    "    feature_result = {'feature': feature}\n",
    "\n",
    "    # Loop over the diff coverage depths\n",
    "    for paper_file, depth in zip(paper_depth_files, paper_depths):\n",
    "        paper_df = pd.read_csv(os.path.join(paper_path, paper_file))\n",
    "        paper_df['tissue'] = paper_df['tissue'].str.lower()\n",
    "        paper_df['cell_type'] = paper_df['cell_type'].apply(\n",
    "        lambda x: '_'.join(x.rsplit('_', 2)[:-2] + [x.rsplit('_', 2)[-2].lower(), x.rsplit('_', 2)[-1].lower()]) if x.count('_') >= 2 else x.lower()\n",
    "        )\n",
    "\n",
    "        # Calculate median rank per cell_type for current cov depth\n",
    "        paper_median = paper_df.groupby('cell_type')['rank'].median().reset_index().rename(columns={'rank': f'median_rank_{depth}'})\n",
    "\n",
    "        # Merge on cell_type\n",
    "        merged_df = pd.merge(my_median, paper_median, on='cell_type')\n",
    "\n",
    "        my_ranks = merged_df['median_rank_my']\n",
    "        paper_ranks = merged_df[f'median_rank_{depth}']\n",
    "\n",
    "        # Paired rank sum test (Wilcoxon signed-rank)\n",
    "        if len(my_ranks) >= 5:  # Wilcoxon requires at least 5 non-zero differences\n",
    "            try:\n",
    "                w_stat, w_p = wilcoxon(my_ranks, paper_ranks)\n",
    "                feature_result[f'corr_{depth}'] = w_stat\n",
    "                feature_result[f'pval_{depth}'] = w_p\n",
    "            except ValueError:\n",
    "                feature_result[f'corr_{depth}'] = None\n",
    "                feature_result[f'pval_{depth}'] = None\n",
    "        else:\n",
    "            feature_result[f'corr_{depth}'] = None\n",
    "            feature_result[f'pval_{depth}'] = None\n",
    "\n",
    "    summary_results.append(feature_result)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "summary_df.to_csv('/mnt/c/Users/donna/Downloads/Thesis/rankjes/abscor_rank_wilcoxon.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4c9ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "my_path = '/mnt/c/Users/donna/Downloads/Thesis/rankjes/abscor_ranks_per_feature'\n",
    "paper_path = '/mnt/c/Users/donna/Downloads/Thesis/rankjes/paper_ranks'\n",
    "\n",
    "# Extract coverage depths\n",
    "paper_depth_files = [f for f in os.listdir(paper_path) if f.endswith('.csv')]\n",
    "paper_depths = [f.split('_')[0] for f in paper_depth_files] \n",
    "\n",
    "summary_results = []\n",
    "\n",
    "# Loop over your fragment feature CSVs\n",
    "for my_file in os.listdir(my_path):\n",
    "    if not my_file.endswith('.csv'):\n",
    "        continue\n",
    "    feature = my_file.split('_results')[0]\n",
    "    my_df = pd.read_csv(os.path.join(my_path, my_file))\n",
    "\n",
    "    # Calculate median rank per cell_type for current feature\n",
    "    my_median = my_df.groupby('cell_type')['rank'].median().reset_index().rename(columns={'rank': 'median_rank_my'})\n",
    "\n",
    "    feature_result = {'feature': feature}\n",
    "\n",
    "    # Loop over the diff coverage depths\n",
    "    for paper_file, depth in zip(paper_depth_files, paper_depths):\n",
    "        paper_df = pd.read_csv(os.path.join(paper_path, paper_file))\n",
    "        paper_df['tissue'] = paper_df['tissue'].str.lower()\n",
    "        paper_df['cell_type'] = paper_df['cell_type'].apply(\n",
    "        lambda x: '_'.join(x.rsplit('_', 2)[:-2] + [x.rsplit('_', 2)[-2].lower(), x.rsplit('_', 2)[-1].lower()]) if x.count('_') >= 2 else x.lower()\n",
    "        )\n",
    "\n",
    "        paper_df['tissue'] = paper_df['tissue'].str.lower()\n",
    "\n",
    "        # Calculate median rank per cell_type for current cov depth\n",
    "        paper_median = paper_df.groupby('cell_type')['rank'].median().reset_index().rename(columns={'rank': f'median_rank_{depth}'})\n",
    "\n",
    "        # Merge on cell_type\n",
    "        # Determine unmatched cell types\n",
    "        my_celltypes = set(my_median['cell_type'])\n",
    "        paper_celltypes = set(paper_median['cell_type'])\n",
    "        shared_celltypes = my_celltypes & paper_celltypes\n",
    "        only_in_my = my_celltypes - paper_celltypes\n",
    "        only_in_paper = paper_celltypes - my_celltypes\n",
    "\n",
    "        if only_in_my or only_in_paper:\n",
    "            print(f\"\\nFeature: {feature}, Depth: {depth}\")\n",
    "            if only_in_my:\n",
    "                print(f\"  Cell types only in your data ({len(only_in_my)}): {sorted(only_in_my)}\")\n",
    "            if only_in_paper:\n",
    "                print(f\"  Cell types only in paper data ({len(only_in_paper)}): {sorted(only_in_paper)}\")\n",
    "\n",
    "        # Merge on shared cell types only\n",
    "        merged_df = pd.merge(my_median, paper_median, on='cell_type')\n",
    "\n",
    "\n",
    "        my_ranks = merged_df['median_rank_my']\n",
    "        paper_ranks = merged_df[f'median_rank_{depth}']\n",
    "\n",
    "        # Mannâ€“Whitney U test (non-paired)\n",
    "        if len(my_ranks) >= 3 and len(paper_ranks) >= 3:\n",
    "            try:\n",
    "                u_stat, u_p = mannwhitneyu(my_ranks, paper_ranks, alternative='two-sided')\n",
    "                feature_result[f'corr_{depth}'] = u_stat\n",
    "                feature_result[f'pval_{depth}'] = u_p\n",
    "            except ValueError:\n",
    "                feature_result[f'corr_{depth}'] = None\n",
    "                feature_result[f'pval_{depth}'] = None\n",
    "        else:\n",
    "            feature_result[f'corr_{depth}'] = None\n",
    "            feature_result[f'pval_{depth}'] = None\n",
    "\n",
    "    summary_results.append(feature_result)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "summary_df.to_csv('/mnt/c/Users/donna/Downloads/Thesis/rankjes/abscor_rank_mannwhitney.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "429419db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554fa37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_std",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
